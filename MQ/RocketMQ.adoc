:toc:

// 保证所有的目录层级都可以正常显示图片
:path: MQ/
:imagesdir: ../image/

// 只有book调用的时候才会走到这里
ifdef::rootpath[]
:imagesdir: {rootpath}{path}{imagesdir}
endif::rootpath[]

== RocketMQ

在现实生活中，并不是所有消息都是生产了之后就立马投递给消费者。比如你定了杯奶茶，但是不想商家立马配送，而是想中午再让商家派送。

image::mq/image-2024-10-16-14-27-27-791.png[]

那么问题来了，有没有解决方案呢？
当然有，没有什么是一个中间层解决不了的，如果有，那就再加一层。
解决这样问题的中间件就是-RocketMQ。

image::mq/image-2024-09-26-15-20-11-076.png[]

=== RocketMQ是什么？

RocketMQ是阿里自研的国产消息队列，目前已经是Apache的顶级项目，和其他消息队列一样，它接收来自生产者的消息，将消息分类，每一个类都是一个topic，消费者根据需要订阅topic，获取里面的消息。

image::mq/image-2024-09-26-16-41-58-161.png[]

是不是很像kafka，因为RocketMQ很多功能就是借鉴的kafka，那么问题很自然就来了，既然RocketMQ借鉴了kafka又很多功能都相同，那他们之间的区别又是什么呢？

=== RocketMQ 和 Kafka的区别

RocketMQ 的架构是参考了kafka的设计思想，但同时又在kafka的基础上做了些调整。
这些调整总结来说就是和Kafka相比，架构上做了减法，但是在功能上做了加法。

*在架构上做减法*

在开始RocketMQ之前先来回顾一下kafka的架构。

kafka中通过topic对消息进行分类。

.增加生产者和消费者
image::mq/image-2024-09-23-16-38-46-657.png[]

为了提升单个topic的并发性能，将单个topic拆分为多个partition

.多分区
image::mq/image-2024-09-23-17-24-09-993.png[]

- 为了提升系统扩展性，将多个partition分别部署在不同的broker上
- 为了提升系统的可用性，为partition加了多个副本
- 为了协调和管理kafka集群的数据信息，引入zookeeper作为协调节点

.kafka模型
image::mq/image-2024-09-26-14-39-01-956.png[]

kafka本身已经是一个非常强的消息队列了，我们接下来看看RocketMQ在kafka的架构基础上，还能玩出什么花样来。

==== 简化协调节点

zookeeper在kafka架构中会和broker进行通信，维护kafka集群信息，一个新的broker连接上zookeeper上之后，其他的broker就能立马感知到它的加入，像这种能在分布式环境中让多个实例获取到同一份信息的服务，就是所谓的分布式协调服务。


.zookeeper管理
image::mq/image-2024-09-26-14-19-34-857.png[]

但是zookeeper作为一个通用的分布式协调服务，它不仅可以用于服务注册和发现，还可以用于分布式锁、配置管理等场景，kafka其实只是用到了部分功能，对于整个系统来说就好比杀鸡用牛刀，太重了。

所以在RocketMQ中直接将zookeeper去掉，换成了nameserver，是一种更加轻量式，管理消息队列的集群消息，生产者通过nameserver获取得到topic和broker的路由信息，然后与各个Broker进行通讯，实现服务发现和负载均衡的效果。

image::mq/image-2024-10-27-21-06-26-168.png[]

当然开发kafka的大佬们也意识到了zookeeper过重的问题，所以从2.8.0版本就支持将zookeeper移出，通过broker之间添加一致性算法raft实现同样的效果，也就是所谓的kRaft或Quorum模式。

image::mq/image-2024-10-27-21-11-38-731.png[]

我们知道kafka将topic拆分成多个partition用来提升并发性能，在RocketMq中也将主题拆分成了多个分区，但是换了个名字，叫Queue也就是队列。

image::mq/image-2024-10-27-21-14-36-324.png[]

kafka中的Partition会存储完整的消息体，而RocketMQ中的Queue上却只存储了一些简要的信息，比如消息偏移量offset，而完整的消息数据存储在一个叫做 `commitlog` 的文件上，我们通过offset可以定位到commitlog上的某条消息。

kafka的消费消息，broker只需要从partition读取消息返回就好了，也就是读取依次就够了。

image::mq/image-2024-10-27-21-21-26-132.png[]

但是在RocketMQ中，broker则需要从queue上读取offset信息的值，再跑到commitlog上将完整的数据读取出来，也就是需要读取两次。

image::mq/image-2024-10-27-21-29-51-426.png[]

那么问题来了，看起来kafka的设计更加高效，为什么RocketMq不采用kafka的设计？

那么就不得不说一下说kafka的底层存储了























































