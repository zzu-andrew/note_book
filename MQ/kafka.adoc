
:toc:

// 保证所有的目录层级都可以正常显示图片
:path: MQ/
:imagesdir: ../image/

// 只有book调用的时候才会走到这里
ifdef::rootpath[]
:imagesdir: {rootpath}{path}{imagesdir}
endif::rootpath[]


== kafka

Message Queue (MQ)，消息队列中间件，与其说是用来做异步解耦的不如说是一种对tcp、UDP、RPC、http等协议再次封装的上层协议，或者说是一种高级socket。

主要作用：

- 异步解耦
- 削峰填谷

=== 削峰填谷

假设有两个程序A和B，B服务每秒只能处理 100 个消息，但 A 服务却每秒发出 200 个消息，B 服务哪里顶得住，分分钟被压垮。如何解决这个问题-添加一层消息中间件来进行削峰填谷。 这次我们要加的中间层是 消息队列 Kafka。

.kafka消息队列
image::mq/image-2024-09-23-14-21-36-356.png[kafka]

=== 什么是消息队列

如果A直接向B发送，如果B服务每秒能处理的消息个数大于A服务每秒发送的个数，那么会导致B服务部分时候处于空闲状态(工作不饱和)。 +
如果B服务每秒处理的消息个数小于A服务发送的个数，那么B服务就会过载，处理不完的消息只能被B服务丢掉，为了解决这个问题，我们很容易想到给B增加个队列用来缓存消息。

.直连
image::mq/image-2024-09-23-15-04-13-782.png[add queue]

队列一般内部使用链表实现，来不及处理的消息就会在链表中积压，积压就会占用内存，当内存不足时压爆B服务，而且原先发送的所有消息都会随着B服务崩溃重启而丢失。为了解决这个问题，我们可以将队列单独拉出来作为一个独立的进程。

.简单的消息队列
image::mq/image-2024-09-23-15-12-21-251.png[]

这个简陋的单链表实现的消息缓存进程，就是所谓的消息队列。将发送数据的称为生产者，消费数据的称为消费者。 但是这个消息队列过于简陋，根本不存在所谓的高可靠、高性能、高可用、高扩展性，为了实现以上功能，我们需要对这个消息队列进行一下改进。

=== 高性能

B服务性能差导致消息队列中的消息不断积压，为了快速消费消息可以增加消费者，这样消费速度就蹭一下上来了，消费能力高的时候，为了不浪费带宽可以适当增加更多的生产者，提升消息队列的吞吐量。

.增加生产者和消费者
image::mq/image-2024-09-23-16-38-46-657.png[]

随着生产者和消费者都变多，我们会发现它们会同时争抢同一个消息队列，抢不到的一方就得等待，这不纯纯浪费时间吗！有解决方案吗？有！首先是对消息进行分类，每一类是一个 topic，然后根据 topic 新增队列的数量，生产者将数据按 topic 投递到不同的队列中，消费者则根据需要订阅不同的 topic。这就大大降低了 topic 队列的压力。

.多个topic
image::mq/image-2024-09-23-17-06-00-950.png[topics]

但单个 topic 的消息还是可能过多，我们可以将单个队列，拆成好几段，每段就是一个 partition分区，每个消费者负责一个 partition。这就大大降低了争抢，提升了消息队列的性能。

.多分区
image::mq/image-2024-09-23-17-24-09-993.png[]

=== 高扩展性

随着topic数量和partition的增加，单个机器可能会因为内存以及CPU资源有限成为限制，从而影响消息队列的整体性能。

.one broker
image::mq/image-2024-09-24-15-28-57-454.png[]

因此，我们可以考虑将分区放到不同机器上，将同一个主题不同的分区(Partition)分布到不同的机器上，我们将这种部署了分区的机器称为broker，通过部署多态机器，我们能极大的缓解因为CPU、内存等资源导致的消息队列性能下降等问题。

.more brokers
image::mq/image-2024-09-24-15-34-08-363.png[]

=== 高可用

高可用说白了就是灾备，如上图如果一个分区所在的broker节点挂了，那么broker里面所有的消息就丢失了，那么消息队列所谓的高可用也就无从谈起。有办法解决吗？渣男都知道多搞几个备胎，身为程序员的你又怎么能不给分区整几个备胎呢？我们可以为每个分区都分配几个备胎，说专业点叫副本(replicas)。因此，每隔分区又被分区Leader和Follower。Leader负责应对生产者和消费者的读写请求，Follower只管同步Leader的消息。

.主备机分区
image::mq/image-2024-09-24-21-14-51-364.png[]

如果主备分区在同一台主机上，那么这台主机挂了还是会导致该分区不可用，我们可以将副本放到和分区的主在不同的主机上，这样就能有效避免因为一条主机挂掉导致该分区直接不可用的情况，只有这样才是真正实现了高可用。

.主备在不同主机上
image::mq/image-2024-09-26-10-28-56-757.png[]

当副本在不同主机上之后，如果原先的分区挂了，那么会在副本Follower所在的分区选举出一个新的主分区Leader partition，这样就实现了消息的灾备，保证了消息队列的高可用性。

.灾备实现
image::mq/image-2024-09-26-10-31-00-800.png[]

=== 持久化和过期策略

当消息队列的分区都有灾备时，那么单个主机的挂掉不会影响消息队列的高可用性，但是如果所有的broker都挂了，那么原先保存在消息队列中的消息就会全部都丢失了。为了解决这个问题我们不能只把数据存储到内存里，还要持久化到磁盘中，这样哪怕所有的broker都挂了，数据也不会丢失，系统重启之后，消息队列能从磁盘中读出数据，继续工作。

.分区数据持久化
image::mq/image-2024-09-26-10-44-03-437.png[]

持久化之后消息队列就不再惧怕主机挂了或者重启了，但是新的问题又来了。随着消息队列的运行，持久化的数据越来越多，有一天终于把所有磁盘空间都占用了，这样依然会导致消息队列不可用，所以我们需要对数据添加保留策略，也就是所谓的retention policy，用来决定哪些数据能保留哪些数据能删除，比如磁盘数据超过一定大小开始删除，或者消息放置一段时间之后会被清理掉。

=== consumer group

到这里，消息队列针对广播消费已经接近完美了，但是还有一个问题，假如A和B两个人来完成老板安排的任务，那么同一个任务只需要交个一个人完成就行了，另外一个人去完成其他任务，只有这样才能达到资源的最优比。消息队列中也需要引入消费者组的概念，只要A和B是同一个组的，那么在消费消息时同一个消息只会有一个收到。这样消息队列只需要按照消费者组来保存消费者偏移量，就能保证各个消费者组内消息不重复也不会丢失。

加入消费者组（consumer group）的概念之后，不同消费者组维护自己的消费进度，互不打搅。

.消费者组
image::mq/image-2024-09-26-11-49-35-412.png[]

=== zookeeper

节点和组件太多，可以使用zookeeper组件来管理数据和状态，他会定期和broker进行通讯，以此判断某些broker是不是跪了，某些消费到哪里了。

.zookeeper管理
image::mq/image-2024-09-26-14-19-34-857.png[]

到了这里一个简陋的消息队列已经成为一个高性能、高扩展性、高可用，并且支持持久化的消息队列，这个就是我们所熟知的kafka，partition以及broker等相关概念都是出自于kafka。

.kafka模型
image::mq/image-2024-09-26-14-39-01-956.png[]

=== kafka应用场景

开篇就说了消息队列主要的作用就是削峰填谷以及异步解耦，消息队列是异步场景中最常用的中间件之一，也被称为分布式万金油，比如上流空间流量忽高忽低，想要削峰填谷，提升cpu/gpu的利用率，用它。系统比较庞大，消息流向盘根错节，想要拆解组件降低系统耦合性，用它。秒杀活动，请求激增，想要保护服务的同时又不影响用户，还得用它。当然凡事无绝对，具体方案还是得根据具体情况而定，做架构做到最后，就是在做折中。

=== 总结

• kafka 是消息队列，像消息队列投递消息的是生产者，消费消息的是消费者。增加生产者和消费者的实例个数可以提升系统吞吐。多个消费者可以组成一个消费者组，不同消费者组维护自己的消费进度，互不打搅。

• kafka 将消息分为多个 topic，每个 topic 内部拆分为多个 partition，每个 partition 又有自己的副本，不同的 partition 会分布在不同的 broker 上，提升性能的同时，还增加了系统可用性和可扩展性。









=== `kafka`集群的架构

1. `broker`
2. topic
3. partition：分区，把同一个`topic`分成不同的分区，提高负载
   - leader 分区的主节点
   - follower 分区的从节点(小弟)
4. Consumer Group

=== 生产者往`kafka`发送数据流的流程(6步)

![image-20210313222030658](image/image-20210313222030658.png)

=== `kafka`选择分区模式(3种)

1. 指定往哪个分区写
2. 指定`Key`，`kafka`根据`key`做`hash`然后决定写哪个分区
3. 轮询方式

=== 生产者往`kafka`发送数据的模式(3)种

1. 0把数据发送给`Leader`就成功，效率最高，安全性最低
2. 1把数据发送给`Leader`，等待`leader`回`ACK`
3. `all`把数据发送给`leader`确保`follower`拉取数据回复`ack`给`Leader`，`Leader`再回复`ACK`；安全性最高




=== `kafka`的启动和创建`topic`


[kafka启动和创建topic](https://www.cnblogs.com/cq-yangzhou/p/11425047.html)

https://mp.weixin.qq.com/s/SNMmCMV-gqkHtWS0Ca3j4g[小白debug什么是kafka]

[kafka](https://www.cnblogs.com/qingyunzong/p/9004509.html)